{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf2ff9-24b1-420a-b86f-c336e2351233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weight Matrix W:\n",
      " [[ 2. -2.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "\n",
      "Recall using x = [1, -1, 1]:\n",
      "Recalled x: [1 1 1]\n",
      "Recalled y: [ 1 -1]\n",
      "\n",
      "Recall using y = [-1, 1]:\n",
      "Recalled x: [1 1 1]\n",
      "Recalled y: [ 1 -1]\n"
     ]
    }
   ],
   "source": [
    "'''ASSIGNMENT 5\n",
    "\n",
    "TITLE: BIDIRECTIONAL ASSOCIATIVE MEMORY\n",
    "PROBLEM STATEMENT: -\n",
    "Write a python Program for Bidirectional Associative Memory with two pairs of vectors. '''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Step 0: Activation function (sign function)\n",
    "def sign(x):\n",
    "    return np.where(x >= 0, 1, -1)\n",
    "\n",
    "# Step 1: Training data (2 pairs of vectors)\n",
    "x_pairs = [np.array([1, -1, 1]), np.array([-1, -1, 1])]  # X inputs\n",
    "y_pairs = [np.array([1, -1]), np.array([-1, 1])]         # Y outputs\n",
    "\n",
    "# Step 2: Initialize weight matrix to zero and train it using Hebbian rule\n",
    "def train_bam(x_list, y_list):\n",
    "    n = len(x_list[0])\n",
    "    m = len(y_list[0])\n",
    "    W = np.zeros((n, m))\n",
    "    for x, y in zip(x_list, y_list):\n",
    "        W += np.outer(x, y)\n",
    "    return W\n",
    "\n",
    "# Train the BAM\n",
    "W = train_bam(x_pairs, y_pairs)\n",
    "\n",
    "# Step 3: BAM recall function\n",
    "def recall_bam(x_input=None, y_input=None, W=None, max_iter=10):\n",
    "    x = x_input.copy() if x_input is not None else np.zeros(W.shape[0])\n",
    "    y = y_input.copy() if y_input is not None else np.zeros(W.shape[1])\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        y_new = sign(np.dot(x, W))       # Step 4\n",
    "        x_new = sign(np.dot(W, y_new))   # Step 5\n",
    "        \n",
    "        if np.array_equal(x, x_new) and np.array_equal(y, y_new):  # Step 6\n",
    "            break\n",
    "        \n",
    "        x, y = x_new, y_new\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "# Test the BAM\n",
    "print(\"Trained Weight Matrix W:\\n\", W)\n",
    "\n",
    "# Try recalling using only x\n",
    "x_test = np.array([1, -1, 1])\n",
    "x_result, y_result = recall_bam(x_input=x_test, W=W)\n",
    "print(\"\\nRecall using x = [1, -1, 1]:\")\n",
    "print(\"Recalled x:\", x_result)\n",
    "print(\"Recalled y:\", y_result)\n",
    "\n",
    "# Try recalling using only y\n",
    "y_test = np.array([-1, 1])\n",
    "x_result, y_result = recall_bam(y_input=y_test, W=W)\n",
    "print(\"\\nRecall using y = [-1, 1]:\")\n",
    "print(\"Recalled x:\", x_result)\n",
    "print(\"Recalled y:\", y_result)\n",
    "\n",
    "\n",
    "\n",
    "'''Here are the detailed answers to your questions on the Bidirectional Associative Memory (BAM) model:\n",
    "\n",
    "---\n",
    "\n",
    "**1. What are the key components of a BAM model?**\n",
    "The **Bidirectional Associative Memory (BAM)** model is a type of recurrent neural network used for associative memory tasks. Its key components include:\n",
    "\n",
    "* **Input Layer (X):** Stores input patterns.\n",
    "* **Output Layer (Y):** Stores associated output patterns.\n",
    "* **Weight Matrix (W):** A matrix that connects the input and output layers.\n",
    "* **Activation Function:** Usually a sign function (e.g., sign(x)) used to compute the final output.\n",
    "* **Bidirectional Association:** Supports recall in both X → Y and Y → X directions.\n",
    "\n",
    "---\n",
    "\n",
    "**2. How do you represent vectors in Python, and what data structures would you use to store them for this program?**\n",
    "In Python, vectors can be represented using:\n",
    "\n",
    "* **Lists:** Simple to use, e.g., `x = [1, -1, 1]`\n",
    "* **NumPy arrays:** Efficient for numerical operations, e.g., `x = np.array([1, -1, 1])`\n",
    "\n",
    "For a BAM program, **NumPy arrays** are preferred because they allow efficient matrix multiplication and vectorized operations, which are central to BAM computations.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Can you describe the process of initializing and training a BAM model with two pairs of vectors?**\n",
    "Yes. Here's how you initialize and train a BAM model with two pairs of associated vectors:\n",
    "\n",
    "Let’s say:\n",
    "\n",
    "* Input vectors: `X1, X2`\n",
    "* Output vectors: `Y1, Y2`\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Convert each pair (Xi, Yi) into column vectors.\n",
    "2. For each pair, compute the outer product: `Wi = Xi.T * Yi`\n",
    "3. Sum all the outer products to form the **weight matrix**:\n",
    "   `W = W1 + W2`\n",
    "4. The matrix `W` is now used for associative recall in both directions:\n",
    "\n",
    "   * `Y = sign(X @ W)` and `X = sign(Y @ W.T)`\n",
    "\n",
    "---\n",
    "\n",
    "**4. What mathematical operations are involved in the activation and update functions of the BAM algorithm?**\n",
    "The core mathematical operations in BAM include:\n",
    "\n",
    "* **Outer Product:** Used during training to compute weight updates.\n",
    "* **Matrix Multiplication:** Used for activation/retrieval during recall.\n",
    "* **Sign Function (Activation):** Converts weighted sum to bipolar output (1 or -1).\n",
    "\n",
    "For example:\n",
    "\n",
    "* Activation: `Y = sign(X @ W)`\n",
    "* Update: `W += X.T @ Y`\n",
    "\n",
    "---\n",
    "\n",
    "**5. Can you discuss the role of the weight matrix in the BAM model and how it is updated during the learning process?**\n",
    "The **weight matrix (W)** stores the associations between input and output vectors. It plays a central role in both training and recall.\n",
    "\n",
    "* **During training:**\n",
    "  For each input-output pair `(X, Y)`, the weight matrix is updated using:\n",
    "  `W = W + X.T @ Y`\n",
    "\n",
    "* **During recall:**\n",
    "  The matrix is used to compute the associated vector:\n",
    "\n",
    "  * Forward recall: `Y = sign(X @ W)`\n",
    "  * Backward recall: `X = sign(Y @ W.T)`\n",
    "\n",
    "The matrix remains symmetric in a simplified BAM model.\n",
    "\n",
    "---\n",
    "\n",
    "**6. How do you handle noise or errors in the input vectors in the context of BAM?**\n",
    "To handle noise or corrupted inputs in BAM:\n",
    "\n",
    "* **Redundancy in Training:** Train with more pairs to improve robustness.\n",
    "* **Bipolar Encoding:** Use -1 and 1 instead of 0 and 1 to reduce ambiguity.\n",
    "* **Iterative Updates:** Alternate between X → Y and Y → X updates until convergence.\n",
    "* **Thresholding (sign function):** Helps remove minor noise by focusing on dominant signals.\n",
    "* **Error Correction:** BAM naturally performs some error correction by converging to the closest stored pattern.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like a working Python code example to demonstrate BAM with two vector pairs?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c11963-ada1-4679-972d-0cbd9bad383d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
