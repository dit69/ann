{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.4469 - val_accuracy: 0.9665 - val_loss: 0.1230\n",
      "Epoch 2/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.1145 - val_accuracy: 0.9733 - val_loss: 0.0885\n",
      "Epoch 3/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0693 - val_accuracy: 0.9718 - val_loss: 0.0945\n",
      "Epoch 4/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0520 - val_accuracy: 0.9753 - val_loss: 0.0794\n",
      "Epoch 5/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0396 - val_accuracy: 0.9792 - val_loss: 0.0777\n",
      "Epoch 6/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0330 - val_accuracy: 0.9753 - val_loss: 0.0891\n",
      "Epoch 7/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0281 - val_accuracy: 0.9772 - val_loss: 0.0911\n",
      "Epoch 8/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0237 - val_accuracy: 0.9793 - val_loss: 0.0770\n",
      "Epoch 9/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0172 - val_accuracy: 0.9780 - val_loss: 0.0938\n",
      "Epoch 10/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9948 - loss: 0.0154 - val_accuracy: 0.9770 - val_loss: 0.0908\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9748 - loss: 0.0996  \n",
      "\n",
      "Test Loss: 0.0899\n",
      "Test Accuracy: 0.9779\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Group C: Assignment No. 13\n",
    "Assignment Title: MNIST Handwritten Character Detection using PyTorch,\n",
    "Keras and Tensorflow\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 2. Preprocess the data\n",
    "# Normalize pixel values (0 to 1)\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Flatten images to vectors of 784 elements (28x28)\n",
    "X_train = X_train.reshape(-1, 28 * 28)\n",
    "X_test = X_test.reshape(-1, 28 * 28)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# 3. Build the model\n",
    "model = models.Sequential([\n",
    "    tf.keras.Input(shape=(784,)),  # Input layer for 28x28 flattened\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # 10 classes for digits 0–9\n",
    "])\n",
    "\n",
    "# 4. Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 5. Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# 6. Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''Here are **important Viva/Oral questions** your teacher might ask based on **Assignment 13: MNIST Handwritten Character Detection using PyTorch, Keras, and TensorFlow**, along with concise and accurate **answers**:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **What is the MNIST dataset?**\n",
    "\n",
    "**Answer:**\n",
    "MNIST (Modified National Institute of Standards and Technology) is a large dataset of handwritten digits from 0 to 9. It contains 60,000 training images and 10,000 test images, each of 28x28 pixels in grayscale. It is widely used for training and testing image processing systems, especially in machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Why is MNIST a good starting dataset for image classification tasks?**\n",
    "\n",
    "**Answer:**\n",
    "MNIST is simple, well-structured, and small in size, making it easy to train and test models quickly. It also provides a clear benchmarking task for evaluating classification algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **What libraries did you use for this project, and why?**\n",
    "\n",
    "**Answer:**\n",
    "I used **Keras**, **TensorFlow**, and **PyTorch**:\n",
    "\n",
    "* Keras for its simplicity and modularity in building neural networks.\n",
    "* TensorFlow as the backend engine for computation.\n",
    "* PyTorch for its dynamic computation graph and ease of debugging.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **What preprocessing steps did you perform on the dataset?**\n",
    "\n",
    "**Answer:**\n",
    "I normalized the pixel values by dividing by 255 to scale them to the range \\[0, 1], and reshaped the input data to add a channel dimension, changing the shape to (28, 28, 1) for CNN input.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Explain the architecture of your CNN model.**\n",
    "\n",
    "**Answer:**\n",
    "The model includes:\n",
    "\n",
    "* **Convolutional layers** to extract features from the images.\n",
    "* **Pooling layers** to reduce dimensionality.\n",
    "* **Dropout layer** to prevent overfitting.\n",
    "* **Dense layers** at the end for classification, with softmax activation in the final layer for predicting digit classes (0–9).\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Which optimizer and loss function did you use?**\n",
    "\n",
    "**Answer:**\n",
    "I used the **Adadelta** optimizer and **categorical cross-entropy** as the loss function, which is suitable for multi-class classification problems like digit recognition.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **What accuracy did your model achieve?**\n",
    "\n",
    "**Answer:**\n",
    "The model achieved approximately **99% accuracy** on the test data, which is expected for CNN models trained on MNIST due to its clean and balanced dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **How did you evaluate the model?**\n",
    "\n",
    "**Answer:**\n",
    "I used the `model.evaluate()` function to test the model on the test dataset, which returns metrics like loss and accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. **Why do we use a Dropout layer?**\n",
    "\n",
    "**Answer:**\n",
    "Dropout is used to reduce overfitting by randomly deactivating a set of neurons during training. This forces the network to learn more robust features.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. **How did you create the GUI for digit prediction?**\n",
    "\n",
    "**Answer:**\n",
    "I used **Tkinter**, a standard Python GUI library. The GUI allows the user to draw a digit on a canvas. The `predict_digit()` function captures the drawing, processes it into a format compatible with the model, and then predicts the digit.\n",
    "\n",
    "---\n",
    "\n",
    "### 11. **Difference between PyTorch and TensorFlow?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "* **TensorFlow** uses a static computation graph (in TF1) but now supports eager execution (like PyTorch).\n",
    "* **PyTorch** uses a dynamic computation graph, which is easier to debug and feels more \"Pythonic\".\n",
    "* TensorFlow is more widely used in production; PyTorch is more popular in research.\n",
    "\n",
    "---\n",
    "\n",
    "### 12. **Why do we use CNN instead of regular neural networks for image data?**\n",
    "\n",
    "**Answer:**\n",
    "CNNs take advantage of spatial relationships in image data using convolution and pooling layers. Unlike regular neural networks that flatten input, CNNs maintain spatial hierarchy, making them more accurate for image classification tasks.\n",
    "\n",
    " '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
